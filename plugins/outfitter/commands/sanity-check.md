---
description: Challenge complexity and find simpler alternatives before implementing
argument-hint: [proposed solution or approach to evaluate]
---

# Challenge Complexity

Evaluate the proposed solution for unnecessary complexity before committing to it.

## Instructions

- Consider the recent conversation history, your context, and the proposal to be evaluated.
- Specific user instructions should be followed unless they are contradictory to the task at hand. $ARGUMENTS

## Steps

1. **Load** â€” Use the Skill tool and load the `outfitter:sanity-check` skill
2. **Consider** â€” Ultrathink and analyze the proposal, identify initial complexity concerns
3. **Dispatch or Execute** â€” Choose execution path based on available tools:
   - **If Task tool available**: Run the simplify loop (see below)
   - **If Task tool unavailable**: Execute the complexity analysis methodology directly using the loaded skill

## Simplify Loop (when Task tool available)

Run iterative cycles with a persistent skeptic agent until complexity is resolved:

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. ANALYZE â€” Dispatch outfitter:skeptic                    â”‚
â”‚     â””â”€ Examine proposal, identify complexity triggers,      â”‚
â”‚        generate alternatives, return structured findings    â”‚
â”‚                          â†“                                  â”‚
â”‚  2. PRESENT â€” Share findings with user                      â”‚
â”‚     â””â”€ Escalation level, alternatives, probing questions    â”‚
â”‚                          â†“                                  â”‚
â”‚  3. DISCUSS â€” Gather user response                          â”‚
â”‚     â””â”€ User provides context, answers questions,            â”‚
â”‚        or asks skeptic to dig deeper                        â”‚
â”‚                          â†“                                  â”‚
â”‚  4. EVALUATE â€” Determine next action                        â”‚
â”‚     â””â”€ If resolved â†’ Document decision                      â”‚
â”‚     â””â”€ If more analysis needed â†’ Resume skeptic (step 1)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Loop Execution

1. **Initial dispatch** â€” Pass proposal, context, requirements to skeptic
2. **Retrieve results** â€” Use TaskOutput to get structured JSON analysis
3. **Present to user** â€” Share escalation level, alternatives, and probing questions
4. **Gather feedback** â€” User may:
   - Answer probing questions (pass answers back to skeptic)
   - Ask skeptic to examine specific aspects deeper
   - Accept an alternative and proceed
   - Justify complexity with evidence (skeptic validates)
5. **Resume or conclude**:
   - **More analysis needed**: Resume same skeptic agent with `resume: {agentId}` and new context
   - **Decision reached**: Document outcome (proceed with simple, proceed with justified complexity, or revisit approach)

### Resumable Skeptic Pattern

The skeptic maintains context across invocations via the `resume` parameter:

```text
Initial dispatch:
  â†’ skeptic analyzes proposal
  â†’ returns findings + agentId: "abc123"

User provides additional context:
  â†’ resume skeptic with { resume: "abc123" }
  â†’ skeptic refines analysis with new information

User asks about specific concern:
  â†’ resume skeptic with { resume: "abc123" }
  â†’ skeptic digs deeper on that aspect
```

This preserves the skeptic's understanding of the proposal through multiple rounds of refinement.

## The Framework

1. IDENTIFY â€” what complexity is being proposed?
2. ALTERNATIVE â€” what's the simplest thing that could work?
3. QUESTION â€” why isn't the simple approach sufficient?
4. DOCUMENT â€” if complexity is justified, record why

## Context Handoff (for initial dispatch)

When dispatching to the skeptic subagent, include:
- The proposed solution or approach
- Current requirements and constraints
- Any justifications already offered
- Team/project context if relevant

When resuming the skeptic, include:
- User's answers to probing questions
- Additional context or constraints revealed
- Specific areas to examine further
- Evidence offered to justify complexity

## Red Flag Rationalizations

Watch for these justifications â€” they usually indicate unjustified complexity:

- "We might need this later"
- "It's more flexible this way"
- "This is how X company does it"
- "It's the industry standard"
- "We should do it right the first time"

## Verdicts and Outcomes

The skeptic returns one of three verdicts:

| Verdict | Meaning | Action |
|---------|---------|--------|
| **proceed** | Complexity is minor (ğŸŸ¡) | Note alternatives, continue |
| **caution** | Complexity is moderate (ğŸŸ ) | Discuss before proceeding |
| **block** | Complexity is high risk (ğŸ›‘) | Address concerns first |

After discussion, document the outcome:
- **Simplified**: Chose simpler alternative
- **Justified**: Complexity validated with evidence, documented in ADR
- **Deferred**: Needs more investigation, created follow-up task

The goal is NOT to reject all complexity â€” it's to ensure complexity is justified by evidence, not speculation.
